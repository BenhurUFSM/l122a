## Implementação de números

A tecnologia usada atualmente para implementar computadores digitais utiliza circuitos eletrônicos.
Os números que são manipulados por essas máquinas devem ser implementados usando grandezas que são processáveis por essas máquinas.
A forma mais simples que se encontrou para implementar isso foi usando uma representação em binário, em que um número é implementado por diversos dígitos, e cada dígito pode ter somente dois valores, usualmente representados por `0` e `1`.
A representação de um núemro em binário usa um mecanismo muito semelhanta ao que usamos para representar números na notação decimal: cada dígito tem um valor, que é alterado de acordo com a posição do dígito.

Em decimal, o dígito mais a direita tem peso 1, o dígito à esquerda dele tem peso 10, o seguinte à esquerda tem peso 100 e assim por diante.
Cada dígito tem o peso dez vezes maior que o do dígito à sua direita.

Em binário, usa-se o mesmo princípio, mas a base de mudança dos pesos é 2 e não 10. O dígito mais à direita tem peso 1, o que está à esquerda dele tem peso 2, o anterior tem peso 4, depois 8, 16, etc.
A sequência de dígitos `101` tem o valor cento e um se estiver em decimal e o valor cinco se estiver em binário.
Um dígito em binário é chamado de **bit**.

Para se poder representar uma grandeza útil, é necessário juntar vários desses bits, da mesma forma que se necessita de mais dígitos decimais quando se representa qualquer valor superior à 9.
Um computador tem uma determinada capacidade de armazenamento, ou uma certa quantidade de bits que ele consegue manter em sua memória.
Quanto mais bits se usa para representar um valor, menor é o número de valores que se consegue colocar em determinada memória de computador.
Para dar mais liberdade ao programador, os computadores permitem que se escolha, para cada valor que se vai colocar no computador, a quantidade de bits que vai ser usada (entre algumas configurações oferecidas).
Quanto menos bits se usa para cada valor, mais restrito se fica quanto a gama de valores que se pode trabalhar, mas menos memória se ocupa (ou se pode usar mais valores) e em geral mais rápido é de se operar sobre cada valor.
Os computadores atuais geralmente oferecem 4 possibilidades, 8, 16, 32 ou 64 bits para um valor, ou 1, 2, 4 ou 8 **bytes** (um byte são 8 bits).
Com *n* bits se consegue representar uma gama de *2<sup>n</sup>* valores diferentes (da mesma forma que com *n* dígitos decimais se consegue representar *10<sup>n</sup>* valores diferentes).
As gamas de valores representáveis pelos tamanhos de dados oferecidos são aproximadamente:

| bytes | valores |
| ---: | ---: |
|    1 |  256 |
|    2 | 65 mil |
|    4 | 4 bilhões |
|    8 | 16 quintilhões |

Para cada uma dessas configurações, em geral o processador ainda oferece a oportunidade de se representar valores com ou sem sinal.
Por exemplo, com 8 bits pode-se escolher se se vai representar valores entre 0 e 255 ou entre -128 e 127.

Os valores acima são chamados de números inteiros, por se aproximarem do conjunto de números inteiros da matemática.
Infelizmente eles não são suficientes para muitos usos que se faz de um computador.
Os processadores também oferecem uma forma de se representar números que se aproximam dos reais.
A forma usada é chamada de números de vírgula (ou ponto) flutuante, e é semelhante à notação científica usada para representar números em decimal.
Na notação científica, pode-se representar o número 3,14 como 314 x 10<sup>-2</sup>, ou seja, desloca-se a vírgula de 314 para a esquerda 2 posições.
Escolhendo bem esses dois números (chamados de mantissa e expoente), pode-se representar "qualquer" número real como dois números inteiros.
Dá para fazer o mesmo em binário: o número 1,01 em binário (que corresponde a 1,25 em decimal) pode ser escrito como "101" x 2<sup>-2</sup>.

Em geral, os processadores oferecem duas possibilidades de representação de números em ponto flutuante, uma que usa 4 bytes (3 para mantissa e 1 para o expoente) e uma que usa 8 bytes (6 e meio para mantissa e 1 e meio para o expoente), chamados de precisão simples ou dupla.
A gama aproximada de valores representáveis por cada uma dessas representações está na abaixo:

| precisão | valores aproximados |
| ---: | :--- |
| simples | entre 10<sup>-38</sup> e 10<sup>38</sup>, com 7 dígitos significativos
| dupla   | entre 10<sup>-308</sup> e 10<sup>308</sup>, com 16 dígitos significativos

Os valores podem ser positivos ou negativos.
7 dígitos significativos quer dizer que se consegue representar 1234567 e 1234568 como dois valores diferentes, mas provavelmente 123456789 e 123456790 serão representados como o mesmo valor (ou 0,01234567 e 0,01234568 etc.).

## Tipos de dados em C

Na linguagem C, as representações de valores oferecidas pelos processadores são tratadas como "tipos de dados".
C tem tipos de dados para representar valores inteiros e tipos de dados para representar valores em ponto flutuante.
Os mais comuns estão abaixo, e geralmente correspondem aos tamanhos vistos acima (geralmente, porque a definição da linguagem não diz o tamanho que cada um deve ter, diz que não podem decrescer na ordem abaixo):

| tipo C | número de bytes |
| ---: | ---: |
| **inteiros** 
| char | 1 |
| short | 2 |
| int | 4 |
| long | 8 |
| **ponto flutuante**
| float | 4 |
| double | 8 |


* * *

A aula terminou antes que conseguíssemos usar isso... fica para a próxima.

Um número inteiro é representado em decimal em C (chamado constante inteira) como uma sequência de dígitos decimais, o primeiro não podendo ser 0.
Um número em ponto flutuante é representado por uma sequência de dígitos decimais que contém também um ponto (`.`) e/ou um `e` seguido por mais dígitos.
Podem teambém ter `+` ou `-` para indicar se são positivos ou negativos.

O processador do computador oferece instruções para realizar os diversos tipos de operações aritméticas, mas a linguagem C oferece um símbolo para expressar cada tipo delas (o operador `*` representa qualquer das multiplicações, por exemplo). O compilador deve escolher qual instrução usar, e ele faz essa escolha a cada operação que encontra no programa C, da seguinte forma: se os dois operandos (os dois valores que serão operados pelo operador) são do mesmo tipo, a instrução escolhida será a desse tipo, e o valor calculado também. Se os dois operandos forem de tipos diferentes, ele escolhe entre eles o tipo que está mais abaixo na tabela acima para realizar a operação e para o resultado. O outro valor é convertido para esse tipo antes da operação ser realizada.
Por exemplo:

| expressão | tipo da operação |
| ---: | :--- |
| 3+2       | inteiro |
| 2/4 | inteiro (e o resultado é 0) |
| 2.0/4.0 | ponto flutuante |
| 2/4.0 | ponto flutuante (o 2 é convertido para ponto flutuante antes da operação)
| 2/3/4.0 | a primeira divisão em inteiro (e resulta 0), a segunda em onto flutuante (e resulta 0 também)

*** Exercícios

Refaça os programas da lista anterior, mas corrigindo os que tinham problema no resultado por se operar somente com inteiros.
No `printf`, se usa o formato `%f` para imprimir valores em ponto flutuante, em vez de `%d`, que é usado para inteiros.
